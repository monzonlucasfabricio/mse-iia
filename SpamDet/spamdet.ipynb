{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Scikit-learn nos ofrece una variedad ampliada de modelos Naive Bayes, para este problema usamos MultinomialNB que es pensado para este tipo de problemas\n",
    "from sklearn.naive_bayes import MultinomialNB   \n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) ¿Cuáles son las 10 palabras más encontradas en correos con SPAM y en correos No SPAM? ¿Hay palabras en común? ¿Algunas llaman la atención?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " NO SPAM\n",
      "you : 3541702\n",
      "george : 3527559\n",
      "hp : 2496576\n",
      "will : 1495268\n",
      "your : 1223098\n",
      "hpl : 1204398\n",
      "re : 1159138\n",
      "edu : 800669\n",
      "address : 681569\n",
      "meeting : 604460\n",
      "\n",
      " SPAM\n",
      "you : 4105599\n",
      "your : 2502597\n",
      "will : 997100\n",
      "free : 939790\n",
      "our : 931799\n",
      "all : 732080\n",
      "mail : 635470\n",
      "email : 578759\n",
      "business : 521250\n",
      "remove : 499309\n",
      "\n",
      "\n",
      "La palabra 'will' se repite en ambos grupos de correo\n",
      "La palabra 'your' se repite en ambos grupos de correo\n",
      "La palabra 'you' se repite en ambos grupos de correo\n"
     ]
    }
   ],
   "source": [
    "# Lee el archivo CSV\n",
    "df = pd.read_csv('spambase.csv')\n",
    "resultado = []\n",
    "spam = ['NO SPAM', 'SPAM']\n",
    "for choise in [0,1]:\n",
    "\n",
    "    spam_df = df[df['spam'] == choise]\n",
    "\n",
    "    word_freq_columns = [col for col in spam_df.columns if col.startswith('word_freq_')]\n",
    "\n",
    "    suma_columnas = spam_df[word_freq_columns].sum()\n",
    "\n",
    "    top_10 = suma_columnas.sort_values(ascending=False).head(10)\n",
    "\n",
    "    resultado.append(top_10.to_dict())\n",
    "\n",
    "    print('\\n',spam[choise])\n",
    "    for columna, valor in resultado[choise].items():\n",
    "        print(f\"{columna[10:]} : {valor}\")\n",
    "\n",
    "print(\"\\n\")\n",
    "claves_iguales = set(resultado[0].keys()).intersection(set(resultado[1].keys()))\n",
    "for key in claves_iguales:\n",
    "    print(f\"La palabra '{key[10:]}' se repite en ambos grupos de correo\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Separe el conjunto de datos en un conjunto de entrenamiento y un conjunto de prueba (70% y 30% respectivamente)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenemos los atributos y target\n",
    "X = (df.drop(columns=\"spam\") * 100).astype(int)\n",
    "#X = dataset2.drop(columns=\"spam\")\n",
    "y = df[\"spam\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size = 0.3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Utilizando un clasificador de Bayes ingenuo, entrene con el conjunto de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 510000 is out of bounds for axis 1 with size 434001",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m naives_bayes_student \u001b[38;5;241m=\u001b[39m CategoricalNB()\n\u001b[1;32m      5\u001b[0m naives_bayes_student\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m----> 7\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mnaives_bayes_student\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(y_test, y_pred)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrecisión del modelo: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/MSE/IIA/mse-iia/.venv/lib/python3.9/site-packages/sklearn/naive_bayes.py:102\u001b[0m, in \u001b[0;36m_BaseNB.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    100\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    101\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_X(X)\n\u001b[0;32m--> 102\u001b[0m jll \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_joint_log_likelihood\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_[np\u001b[38;5;241m.\u001b[39margmax(jll, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)]\n",
      "File \u001b[0;32m~/Documents/MSE/IIA/mse-iia/.venv/lib/python3.9/site-packages/sklearn/naive_bayes.py:1513\u001b[0m, in \u001b[0;36mCategoricalNB._joint_log_likelihood\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_):\n\u001b[1;32m   1512\u001b[0m     indices \u001b[38;5;241m=\u001b[39m X[:, i]\n\u001b[0;32m-> 1513\u001b[0m     jll \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_log_prob_\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m   1514\u001b[0m total_ll \u001b[38;5;241m=\u001b[39m jll \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_log_prior_\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m total_ll\n",
      "\u001b[0;31mIndexError\u001b[0m: index 510000 is out of bounds for axis 1 with size 434001"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "naives_bayes_student = CategoricalNB()\n",
    "naives_bayes_student.fit(X_train, y_train)\n",
    "\n",
    "y_pred = naives_bayes_student.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Precisión del modelo: {accuracy:.2f}\")\n",
    "\n",
    "# Generar un reporte de clasificación\n",
    "print(\"Reporte de clasificación:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Utilizando un clasificador de Regresión Logística, entrene con el conjunto de entrenamiento (en este caso, normalice los datos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo: 0.83\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.74      0.85       845\n",
      "           1       0.71      0.98      0.82       536\n",
      "\n",
      "    accuracy                           0.83      1381\n",
      "   macro avg       0.84      0.86      0.83      1381\n",
      "weighted avg       0.87      0.83      0.84      1381\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Lo transformamos en DataFrames\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X.columns)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X.columns)\n",
    "\n",
    "classifier_balance = LogisticRegression(random_state = 0, class_weight=\"balanced\")\n",
    "classifier_balance.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = classifier_balance.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Precisión del modelo: {accuracy:.2f}\")\n",
    "\n",
    "# Generar un reporte de clasificación\n",
    "print(\"Reporte de clasificación:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Calcule la matriz de confusión del conjunto de evaluación para ambos modelos. ¿Qué tipo de error comete más cada modelo? ¿Cuál de los dos tipos de error crees que es más importante para este problema?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
